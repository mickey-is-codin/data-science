{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.nn as nn\n",
    "\n",
    "import keras\n",
    "import keras.datasets as datasets\n",
    "import keras.utils as utils\n",
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Import predefined dataset and create tensors for it\n",
    "mnist = datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstrate the dataset\n",
    "plt.imshow(x_train[0], cmap=plt.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the image pixel data\n",
    "x_train = utils.normalize(x_train, axis=1)\n",
    "x_test  = utils.normalize(x_test,  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model architecture\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Input layer to flatten the image to 1 dimension\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Two hidden layers that are identical\n",
    "model.add(layers.Dense(128, activation=nn.relu))\n",
    "model.add(layers.Dense(128, activation=nn.relu))\n",
    "\n",
    "# Output layer using softmax for a probability distribution\n",
    "model.add(layers.Dense(10, activation=nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mickey/.local/share/virtualenvs/Flow-pySRtaAc/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/mickey/.local/share/virtualenvs/Flow-pySRtaAc/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2587 - acc: 0.9246\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1069 - acc: 0.9667\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0726 - acc: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1512dc0b8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training parameters\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step\n",
      "0.09356558708976954 0.9743\n"
     ]
    }
   ],
   "source": [
    "# Take validation loss and accuract on the testing portion of data\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights of the model super easily\n",
    "model.save('mnist_2_layer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model with the name we just saved\n",
    "new_model_instance = models.load_model('mnist_2_layer.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of raw forward pass results\n",
    "predictions = new_model_instance.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABnlJREFUeJzt3U1LVH0cxvEZFe1BNMikjT1R4KKiNq6Edr2G1r2B3krvpBatWkXQrkWERJG0SKmoRHzASsy5N927zu/cjd6Ten0+yy7OjFDfDvTvzHR7vV4HOPqG/vYPAAyG2CGE2CGE2CGE2CHEyIDfzz/9w/+v+7tfdGeHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEGKHEIP+KGn68ObNm3Lf3t5u3L5+/Vpeu7S0VO5DQ/X9YHZ2ttxPnTrVuF2+fLm8lv3lzg4hxA4hxA4hxA4hxA4hxA4hxA4hnLMfAE+fPi33T58+lXt1zr6zs1NeOzw8XO5t5+yLi4t9Xz85OVlee+bMmXLnz7izQwixQwixQwixQwixQwixQwixQ4hur9cb5PsN9M0OikePHpX76upquY+NjZV7dc5+8uTJ8tqZmZly39raKvcPHz6U++bmZuM2Pj5eXnvnzp1yp1H3d7/ozg4hxA4hxA4hxA4hxA4hxA4hxA4hPM++D+7evVvu165dK/epqalyb3vue35+vnFrO6MfGan/COzu7pb748ePy706Z9/Y2CivZX+5s0MIsUMIsUMIsUMIsUMIsUMIR2/7oO0R1rajt+prjTudTufWrVvlfuzYsXLfi1evXpX72tpa3689NzfX97X8OXd2CCF2CCF2CCF2CCF2CCF2CCF2COGcfR98/vy53NfX18u97Zx8dHT0j3+m/fL+/ftyH/BHkbMH7uwQQuwQQuwQQuwQQuwQQuwQQuwQwjn7AExMTPztH6HRwsJCubf9H4E209PTjdvs7OyeXps/484OIcQOIcQOIcQOIcQOIcQOIcQOIZyzH3FLS0vl/uLFi3IfGqrvB8ePHy/36rPh275Omv3lzg4hxA4hxA4hxA4hxA4hxA4hxA4hnLMfcSsrK+W+1899P3/+fLmfPXt2T6/P/nFnhxBihxBihxBihxBihxBihxCO3o6AJ0+eNG5tj7i2uXTpUrlfv359T6/P4LizQwixQwixQwixQwixQwixQwixQwjn7IfA9+/fy/3Lly+N28+fP8trT5w4Ue5Xr14t95ERf4QOC3d2CCF2CCF2CCF2CCF2CCF2CCF2COGQ9BB49uxZuf/48aPv1257Xn18fLzv1+ZgcWeHEGKHEGKHEGKHEGKHEGKHEGKHEM7ZD4Dl5eVyX11d7fu1274y+caNG32/NoeLOzuEEDuEEDuEEDuEEDuEEDuEEDuEcM4+AG2f+/7y5cty393d7fu9T58+Xe4+9z2HOzuEEDuEEDuEEDuEEDuEEDuEcO4yAM+fPy/3lZWVch8bGyv3mZmZxu3mzZvlteRwZ4cQYocQYocQYocQYocQYocQYocQztkHoO2cve0x1DZzc3ONm0dY+Zc7O4QQO4QQO4QQO4QQO4QQO4QQO4RwCHsEbG9vN25DQ3/37/PR0dHGrdvtltfu7OyU+9bWVrn3er3GbX19vbz2wYMH5b62tlbu3759K/fh4eHG7d69e+W1U1NT5d7EnR1CiB1CiB1CiB1CiB1CiB1CiB1CdKuzyP/BQN/soLh//365tz3P3va58dU5e9tZdXXe+1/2tnP86enpxu3t27flta9fvy73tq+6rs7h274Ge3Jystw/fvxY7m3n8FV3y8vLfV/7y2//A4M7O4QQO4QQO4QQO4QQO4QQO4TwiOsAXLx4sdzbHrc8zN69e9e4PXz4sLx2cXGx3M+dO1fu1bFh25Fi20dw3759u9yvXLlS7tXx2cbGRnltv9zZIYTYIYTYIYTYIYTYIYTYIYTYIYRHXA+AhYWFcm87E64eY237/W17FHNpaanc2x5x3dzc7GvrdOqPoe50Op2JiYlyn5+fb9wuXLhQXnvIecQVkokdQogdQogdQogdQogdQogdQjhnh6PHOTskEzuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEGBnw+3UH/H7AL+7sEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEELsEOIffqAHvZTPBA8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.argmax(predictions[1]))\n",
    "\n",
    "plt.imshow(x_test[1], cmap=plt.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flow",
   "language": "python",
   "name": "flow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
