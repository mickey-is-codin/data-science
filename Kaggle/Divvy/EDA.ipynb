{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago Divvy Bike Ride-Sharing Analysis\n",
    "\n",
    "![alt text](images/divvy.jpg)\n",
    "![alt_text](images/divvy_map.jpg)\n",
    "\n",
    "### Introduction\n",
    "This notebook is based on the [Divvy Ride-Sharing Kaggle dataset and competition](https://www.kaggle.com/yingwurenjian/chicago-divvy-bicycle-sharing-data) for Divvy bike rides in Chicago, IL. It's a re-creation of a program I created about a year ago that was lost when a hard drive died and I've since learned my lesson so this is going straight to git. Some of the features of the previous program will be implemented but I really want to try to divide the notebooks more atomically so that each serves a pretty specific purpose and doesn't have too large of scope. \n",
    "\n",
    "### Goals of the Notebook\n",
    " * Conditionally split dataset\n",
    " * Determine which stations are busiest/where they usually lead to\n",
    " * Show distributions of the data, branch out with Seaborn library\n",
    " * Map rides using Basemap--really improve my skills with that\n",
    " * Perform machine learning and create models using Scikit-Learn\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing \n",
    "Just a typical data science library stack for the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import subprocess\n",
    "\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV File Exploration and Importing\n",
    "\n",
    "The first thing we'll do is peer into the csv files provided by Kaggle to see what kind of data we're looking at. Since the data is incredibly large (don't have a week for operating on 9 million divvy bike rides), for this stage of the analysis we'll just take a random sampling from the data.\n",
    "\n",
    "To randomize the import I'm just going to retrieve every 1/n lines from the file. \n",
    "\n",
    "**Updated 8/20/19:** Changing import methods based on [this kaggle kernel](https://www.kaggle.com/szelee/how-to-import-a-csv-file-of-55-million-rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file contains 9495237 rows\n",
      "CPU times: user 7.51 ms, sys: 36.4 ms, total: 43.9 ms\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "filename = \"data/data.csv\"\n",
    "\n",
    "def file_len(fname):\n",
    "    p = subprocess.Popen(['wc', '-l', fname], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    result, err = p.communicate()\n",
    "    if p.returncode != 0:\n",
    "        raise IOError(err)\n",
    "    return int(result.strip().split()[0]) + 1\n",
    "\n",
    "n_rows = file_len(filename)\n",
    "print('Data file contains {} rows'.format(n_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>...</th>\n",
       "      <th>from_station_id</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>latitude_start</th>\n",
       "      <th>longitude_start</th>\n",
       "      <th>dpcapacity_start</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>latitude_end</th>\n",
       "      <th>longitude_end</th>\n",
       "      <th>dpcapacity_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2355134</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-06-30 23:57:00</td>\n",
       "      <td>2014-07-01 00:07:00</td>\n",
       "      <td>...</td>\n",
       "      <td>131</td>\n",
       "      <td>Lincoln Ave &amp; Belmont Ave</td>\n",
       "      <td>41.939365</td>\n",
       "      <td>-87.668385</td>\n",
       "      <td>15.0</td>\n",
       "      <td>303</td>\n",
       "      <td>Broadway &amp; Cornelia Ave</td>\n",
       "      <td>41.945512</td>\n",
       "      <td>-87.645980</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2355133</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-06-30 23:56:00</td>\n",
       "      <td>2014-07-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>282</td>\n",
       "      <td>Halsted St &amp; Maxwell St</td>\n",
       "      <td>41.864580</td>\n",
       "      <td>-87.646930</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22</td>\n",
       "      <td>May St &amp; Taylor St</td>\n",
       "      <td>41.869482</td>\n",
       "      <td>-87.655486</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2355130</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-06-30 23:33:00</td>\n",
       "      <td>2014-06-30 23:35:00</td>\n",
       "      <td>...</td>\n",
       "      <td>327</td>\n",
       "      <td>Sheffield Ave &amp; Webster Ave</td>\n",
       "      <td>41.921687</td>\n",
       "      <td>-87.653714</td>\n",
       "      <td>19.0</td>\n",
       "      <td>225</td>\n",
       "      <td>Halsted St &amp; Dickens Ave</td>\n",
       "      <td>41.919936</td>\n",
       "      <td>-87.648830</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2355129</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Female</td>\n",
       "      <td>2014-06-30 23:26:00</td>\n",
       "      <td>2014-07-01 00:24:00</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>Peoria St &amp; Jackson Blvd</td>\n",
       "      <td>41.877749</td>\n",
       "      <td>-87.649633</td>\n",
       "      <td>19.0</td>\n",
       "      <td>194</td>\n",
       "      <td>State St &amp; Wacker Dr</td>\n",
       "      <td>41.887155</td>\n",
       "      <td>-87.627750</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2355128</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Female</td>\n",
       "      <td>2014-06-30 23:16:00</td>\n",
       "      <td>2014-06-30 23:26:00</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>Loomis St &amp; Lexington St</td>\n",
       "      <td>41.872187</td>\n",
       "      <td>-87.661501</td>\n",
       "      <td>15.0</td>\n",
       "      <td>134</td>\n",
       "      <td>Peoria St &amp; Jackson Blvd</td>\n",
       "      <td>41.877749</td>\n",
       "      <td>-87.649633</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_id  year  month  week  day  hour    usertype  gender  \\\n",
       "0  2355134  2014      6    27    0    23  Subscriber    Male   \n",
       "1  2355133  2014      6    27    0    23  Subscriber    Male   \n",
       "2  2355130  2014      6    27    0    23  Subscriber    Male   \n",
       "3  2355129  2014      6    27    0    23  Subscriber  Female   \n",
       "4  2355128  2014      6    27    0    23  Subscriber  Female   \n",
       "\n",
       "             starttime             stoptime  ...  from_station_id  \\\n",
       "0  2014-06-30 23:57:00  2014-07-01 00:07:00  ...              131   \n",
       "1  2014-06-30 23:56:00  2014-07-01 00:00:00  ...              282   \n",
       "2  2014-06-30 23:33:00  2014-06-30 23:35:00  ...              327   \n",
       "3  2014-06-30 23:26:00  2014-07-01 00:24:00  ...              134   \n",
       "4  2014-06-30 23:16:00  2014-06-30 23:26:00  ...              320   \n",
       "\n",
       "             from_station_name latitude_start  longitude_start  \\\n",
       "0    Lincoln Ave & Belmont Ave      41.939365       -87.668385   \n",
       "1      Halsted St & Maxwell St      41.864580       -87.646930   \n",
       "2  Sheffield Ave & Webster Ave      41.921687       -87.653714   \n",
       "3     Peoria St & Jackson Blvd      41.877749       -87.649633   \n",
       "4     Loomis St & Lexington St      41.872187       -87.661501   \n",
       "\n",
       "  dpcapacity_start  to_station_id           to_station_name  latitude_end  \\\n",
       "0             15.0            303   Broadway & Cornelia Ave     41.945512   \n",
       "1             15.0             22        May St & Taylor St     41.869482   \n",
       "2             19.0            225  Halsted St & Dickens Ave     41.919936   \n",
       "3             19.0            194      State St & Wacker Dr     41.887155   \n",
       "4             15.0            134  Peoria St & Jackson Blvd     41.877749   \n",
       "\n",
       "   longitude_end dpcapacity_end  \n",
       "0     -87.645980           15.0  \n",
       "1     -87.655486           15.0  \n",
       "2     -87.648830           15.0  \n",
       "3     -87.627750           11.0  \n",
       "4     -87.649633           19.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = pd.read_csv(filename, nrows=5)\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 23 columns):\n",
      "trip_id              5 non-null int64\n",
      "year                 5 non-null int64\n",
      "month                5 non-null int64\n",
      "week                 5 non-null int64\n",
      "day                  5 non-null int64\n",
      "hour                 5 non-null int64\n",
      "usertype             5 non-null object\n",
      "gender               5 non-null object\n",
      "starttime            5 non-null object\n",
      "stoptime             5 non-null object\n",
      "tripduration         5 non-null float64\n",
      "temperature          5 non-null float64\n",
      "events               5 non-null object\n",
      "from_station_id      5 non-null int64\n",
      "from_station_name    5 non-null object\n",
      "latitude_start       5 non-null float64\n",
      "longitude_start      5 non-null float64\n",
      "dpcapacity_start     5 non-null float64\n",
      "to_station_id        5 non-null int64\n",
      "to_station_name      5 non-null object\n",
      "latitude_end         5 non-null float64\n",
      "longitude_end        5 non-null float64\n",
      "dpcapacity_end       5 non-null float64\n",
      "dtypes: float64(8), int64(8), object(7)\n",
      "memory usage: 1.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintypes = {\n",
    "    'trip_id': 'int32',\n",
    "    'year': 'uint16',\n",
    "    'month': 'uint8',\n",
    "    'week': 'uint8',\n",
    "    'day': 'uint8',\n",
    "    'hour': 'uint8',\n",
    "    'usertype': 'str',\n",
    "    'gender': 'str',\n",
    "    'starttime': 'str',\n",
    "    'stoptime': 'str',\n",
    "    'tripduration': 'float32',\n",
    "    'temperature': 'float32',\n",
    "    'events': 'str',\n",
    "    'from_station_id': 'int32',\n",
    "    'from_station_name': 'str',\n",
    "    'latitude_start': 'float32',\n",
    "    'longitude_start': 'float32',\n",
    "    'dpcapacity_start': 'float32',\n",
    "    'to_station_id': 'int32',\n",
    "    'to_station_name': 'str',\n",
    "    'latitude_end': 'float32',\n",
    "    'longitude_end': 'float32',\n",
    "    'dpcapacity_end': 'float32'\n",
    "}\n",
    "cols = list(traintypes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:07,  7.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [01:13, 25.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:40, 25.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [02:41, 35.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [03:45, 44.47s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_list = []\n",
    "\n",
    "for df_chunk in tqdm(\n",
    "    pd.read_csv(\n",
    "        filename, \n",
    "        usecols=cols, \n",
    "        dtype=traintypes, \n",
    "        chunksize=chunksize\n",
    "    )\n",
    "):\n",
    "    df_chunk['starttime'] = df_chunk['starttime'].str.slice(0, 16)\n",
    "    df_chunk['starttime'] = pd.to_datetime(df_chunk['starttime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    df_list.append(df_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Data columns (total 23 columns):\n",
      "trip_id              400000 non-null int32\n",
      "year                 400000 non-null uint16\n",
      "month                400000 non-null uint8\n",
      "week                 400000 non-null uint8\n",
      "day                  400000 non-null uint8\n",
      "hour                 400000 non-null uint8\n",
      "usertype             400000 non-null object\n",
      "gender               400000 non-null object\n",
      "starttime            400000 non-null datetime64[ns, UTC]\n",
      "stoptime             400000 non-null object\n",
      "tripduration         400000 non-null float32\n",
      "temperature          400000 non-null float32\n",
      "events               400000 non-null object\n",
      "from_station_id      400000 non-null int32\n",
      "from_station_name    400000 non-null object\n",
      "latitude_start       400000 non-null float32\n",
      "longitude_start      400000 non-null float32\n",
      "dpcapacity_start     400000 non-null float32\n",
      "to_station_id        400000 non-null int32\n",
      "to_station_name      400000 non-null object\n",
      "latitude_end         400000 non-null float32\n",
      "longitude_end        400000 non-null float32\n",
      "dpcapacity_end       400000 non-null float32\n",
      "dtypes: datetime64[ns, UTC](1), float32(8), int32(3), object(6), uint16(1), uint8(4)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.concat(df_list[0:4])\n",
    "\n",
    "del df_list\n",
    "\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thoughts:** There are a few really interesting features contained within the dataset that I'll want to explore moving foward in this notebook. I'll break the features down sort of categorically here.\n",
    "\n",
    "**Geographical:**\n",
    " * from_station_id\n",
    " * from_station_name\n",
    " * latitude_start\n",
    " * longitude_start\n",
    " * to_station_id\n",
    " * to_station_name\n",
    " * latitude_end\n",
    " * longitude_end\n",
    " \n",
    "**Weather:**\n",
    " * temperature\n",
    " * events\n",
    " \n",
    "**Datetime:**\n",
    " * year\n",
    " * month\n",
    " * week\n",
    " * day\n",
    " * hour\n",
    " * starttime\n",
    " * stoptime\n",
    " * tripduration\n",
    " \n",
    "**User-Specific:**\n",
    " * usertype\n",
    " * gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "There are a couple of columns that we can build from our current set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'displacement'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-eadffad32097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'displacement'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhaversine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3543\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3544\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3545\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3547\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3382\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m                 )\n\u001b[1;32m   2889\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def haversine(row):\n",
    "    lon1 = row['longitude_start']\n",
    "    lat1 = row['latitude_start']\n",
    "    lon2 = row['longitude_end']\n",
    "    lat2 = row['latitude_end']\n",
    "    lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "data_df['displacement'] = data_df.apply(lambda row: haversine(row), axis=1)\n",
    "data_df['rate'] = data_df['displacement'].div(data_df['tripduration']).multiply(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = data_df.drop(\n",
    "    [\n",
    "        'trip_id', \n",
    "        'usertype',\n",
    "        'events',\n",
    "        'from_station_id',\n",
    "        'from_station_name',\n",
    "        'to_station_id',\n",
    "        'to_station_name',\n",
    "        'dpcapacity_start',\n",
    "        'dpcapacity_end'\n",
    "    ], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n >= 1000:\n",
    "    sns.pairplot(num_df)\n",
    "else:\n",
    "    print('Not plotting to save time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts:\n",
    "* Divvy popularity grew over the course of data collection\n",
    "* People like riding bikes in the summer\n",
    "* People take bikes to and from work (9AM and 5PM)\n",
    "* People don't like to ride bikes for more than about 10 minutes\n",
    "* People like riding bikes when it's about 70 degrees out\n",
    "* People seem to ride north more than south\n",
    "* People seem to ride east more than west"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n >= 1000:\n",
    "    g = sns.PairGrid(num_df)\n",
    "    g.map_diag(sns.kdeplot)\n",
    "    g.map_offdiag(sns.kdeplot, n_levels=6)\n",
    "else:\n",
    "    print('Not plotting to save time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Analysis\n",
    "\n",
    "**Vanilla Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(\n",
    "    data_df.temperature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    x='events',\n",
    "    data=data_df,\n",
    "    kind='count',\n",
    "    palette='ch:.25'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    x='events',\n",
    "    y='tripduration',\n",
    "    data=data_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(\n",
    "    data_df['temperature'], \n",
    "    data_df['tripduration'],\n",
    "    kind='kde'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_rides  = data_df[data_df['temperature'] > 80]\n",
    "cold_rides = data_df[data_df['temperature'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.catplot(\n",
    "    x='temperature',\n",
    "    data=hot_rides,\n",
    "    kind='count',\n",
    "    palette='ch:.25',\n",
    "    ax=ax\n",
    ")\n",
    "print(hot_rides['temperature'].value_counts())\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.catplot(\n",
    "    x='temperature',\n",
    "    data=cold_rides,\n",
    "    kind='count',\n",
    "    palette='ch:.25',\n",
    "    ax=ax\n",
    ")\n",
    "print(cold_rides['temperature'].value_counts())\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "    sns.jointplot(\n",
    "        x=data_df['temperature'], \n",
    "        y=data_df['tripduration'], \n",
    "        kind=\"hex\", \n",
    "        color=\"k\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Analysis\n",
    "\n",
    "**Vanilla Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "sns.distplot(data_df.displacement, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "sns.catplot(\n",
    "    x='events',\n",
    "    y='displacement',\n",
    "    data=data_df,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
